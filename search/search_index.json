{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#noisy-neighbor-collector","title":"Noisy Neighbor Collector","text":"<p>A Kubernetes-native collector for monitoring noisy neighbor issues, currently focusing on memory subsystem interference between pods. This project is under active development and we welcome contributors to help build this critical observability component.</p>"},{"location":"#overview","title":"Overview","text":"<p>The Noisy Neighbor Collector helps SREs identify and quantify performance degradation caused by memory subsystem interference (\"noisy neighbors\").</p> <p>This data helps operators: - Quantify the performance impact of noisy neighbors - Determine which pods are causing interference and which are affected - Mitigate interference by isolating high-noise deployments and working with their owners to optimize them</p>"},{"location":"#why-this-matters","title":"Why This Matters","text":"<p>Memory noisy neighbors directly impact application latency, especially at the tail (P95/P99). For example, Google published 5x-14x increases in P95/P99 latency due to memory subsystem interference.</p> <p>Collecting noisy neighbor metrics and reducing tail latency delivers two key benefits:</p> <ol> <li> <p>Better response times for users, improving customer experience and key business metrics. Latency has a direct impact on revenue.</p> </li> <li> <p>More efficient infrastructure through reduced autoscaling. Many scaling decisions are based on P95/P99 metrics. By reducing spikes caused by noisy neighbors, you can run at higher utilization without breaching latency SLOs.</p> </li> </ol> <p>Common sources of interference include: - Garbage collection - Large transactions (e.g. scanning many database records) - Analytics workloads</p>"},{"location":"#security-and-data-collection","title":"Security and Data Collection","text":"<p>The collector is designed with security in mind and has a limited scope of data collection:</p> <p>Only collects CPU profiling data and process metadata: - Performance counters: cycles, instructions, LLC cache misses - Process metadata: process name, process ID (pid), cgroup/container ID</p> <p>Does not access process internals or user data: - No application-level data is accessed or collected</p> <p>You can review our data schema and sample data files to see exactly what is collected. These resources demonstrate the limited scope of the collected data.</p>"},{"location":"#requirements","title":"Requirements","text":"<ul> <li>Kernel version: Minimum 5.15</li> <li>Hardware: Any server with perf counter support (container images are published for x86_64, arm64)</li> <li>for Intel on AWS, an instance that supports \"Hardware\" from this list</li> <li>for Intel on GCP: instance that supports \"Basic Hardware\" from this list</li> <li>Resource utilization:</li> <li>Memory: ~300MB per node</li> <li>CPU: ~1% for eBPF, ~0.75% userspace</li> <li>Storage: ~100MB/hour of collected data (varies with node size; there is a quota configuration option to limit the amount of data collected)</li> </ul> <p>See the benchmark results for more details.</p>"},{"location":"#installation","title":"Installation","text":""},{"location":"#helm-chart","title":"Helm Chart","text":"<p>The easiest way to install the collector is using our Helm chart:</p> <pre><code>helm repo add unvariance https://unvariance.github.io/collector/charts\nhelm repo update\nhelm install collector unvariance/collector \\\n  --set storage.type=\"s3\" \\\n  --set storage.prefix=\"memory-collector-metrics-\" \\\n  --set storage.s3.bucket=\"your-bucket-name\" \\\n  --set storage.s3.region=\"us-west-2\" \\\n  --set storage.s3.auth.method=\"iam\" \\\n  --set serviceAccount.annotations.\"eks\\.amazonaws\\.com/role-arn\"=\"arn:aws:iam::123456789012:role/S3Access\" \\\n  --set collector.storageQuota=\"1000000000\"\n</code></pre> <p>This example shows how to configure the collector with S3 storage using IAM roles for authentication, with a 1GB quota.</p> <p>For complete configuration options, see the Helm chart documentation.</p>"},{"location":"#manual-installation","title":"Manual Installation","text":"<p>See the GitHub Actions workflow for detailed build steps.</p>"},{"location":"#roadmap","title":"Roadmap","text":"<p>We're actively working on:</p> <p>Container Metadata (PR #153 - Capturing container and pod metadata for processes - Exploring Node Resource Interface (NRI) for metadata access</p> <p>Noisy Neighbor Detection - Identifying noisy neighbors from raw 1ms measurements - Aggregating metrics over longer intervals to determine:   - Which pods are noisy vs. sensitive    - % time each pod is noisy or impacted by noise - Quantifying cycles wasted due to noise exposure</p>"},{"location":"#get-involved","title":"Get Involved","text":"<p>We welcome contributions! Here's how you can help:</p> <ul> <li>Code: Check our good first issues and documentation</li> <li>Use Cases: Share interference scenarios, test in your environment  </li> <li>Discussion: Open GitHub issues or reach out - @Jonathan Perry on CNCF Slack</li> <li>Schedule a Chat: https://yonch.com/collector</li> </ul>"},{"location":"#learn-more","title":"Learn More","text":"<ul> <li>KubeCon Europe 2025: The Missing Metrics (video) (slides)</li> <li>KubeCon NA 2024: Love thy (noisy) neighbor (video) (slides) (notes)</li> </ul>"},{"location":"#benchmark-results","title":"Benchmark Results","text":"<p>The collector was benchmarked using the OpenTelemetry Demo application.</p> <p></p> <p></p> <p>See the benchmark results for more details.</p>"},{"location":"#background","title":"Background","text":"<p>This project builds on research and technologies from: - Google's CPI\u00b2 system  - Meta's Resource Control - Alibaba Cloud's Alita - MIT's Caladan  </p>"},{"location":"#license","title":"License","text":"<p>Code is licensed under Apache-2.0. Documentation is licensed under CC BY 4.0.</p>"},{"location":"benchmark/","title":"Memory Collector Benchmark Results","text":"<p>This page presents the latest benchmark results for the Memory Collector, demonstrating its performance characteristics and overhead when running in typical deployment scenarios.</p>"},{"location":"benchmark/#overview","title":"Overview","text":"<p>The benchmark simulates a realistic production environment by gradually ramping up a load generator over 200 seconds, followed by a steady-state period to evaluate collector behavior under sustained load. This approach allows us to measure the collector's resource consumption patterns under various load conditions.</p> <p>All results shown here are automatically published from the most recent successful benchmark run. The benchmark configuration may evolve over time, so specific parameters might differ slightly from those described in this documentation.</p>"},{"location":"benchmark/#workload-performance","title":"Workload Performance","text":"<p>This graph shows the overall performance of the test workload during the benchmark run, displaying: - Request rate (requests per second) - Median latency - P95 latency (95th percentile) - P99 latency (99th percentile)</p>"},{"location":"benchmark/#collector-resource-consumption","title":"Collector Resource Consumption","text":""},{"location":"benchmark/#cpu-utilization","title":"CPU Utilization","text":"<p>This graph displays two key metrics: 1. Collector userspace CPU consumption in millicores as the experiment progresses 2. Total CPU utilization of everything except the collector</p> <p>From these measurements, we can calculate the collector's CPU overhead as a percentage of the total workload. The benchmark uses the <code>pidstats</code> utility to gather these measurements.</p>"},{"location":"benchmark/#memory-utilization","title":"Memory Utilization","text":"<p>This graph shows the memory consumption of the collector over time. The collector processes data in \"row groups,\" compressing measurements into an efficient representation before periodically flushing to storage. Memory usage typically stabilizes between 300-350MB during extended runs as the collection and flushing processes reach equilibrium.</p>"},{"location":"benchmark/#ebpf-overhead","title":"eBPF Overhead","text":"<p>The benchmark captures eBPF overhead through sampling profiles, which are converted to flame graphs. To analyze the percentage of samples attributed to eBPF processing, look for the <code>bpf_prog</code> symbol in the flame graph:</p> <p></p>"},{"location":"benchmark/#collected-data-examples","title":"Collected Data Examples","text":"<p>The collector stores measurements in Parquet format with a well-defined schema. Here are links to sample data and schema information:</p> <ul> <li>Simple Schema - Basic schema structure</li> <li>Sample Records (100) - 100 representative records</li> <li>First Records (Head) - First 100 records from the dataset</li> <li>Detailed Schema - Complete schema with column descriptions (note that this includes column descriptions that are repeated for each row group in the Parquet file)</li> </ul>"},{"location":"benchmark/#data-measured-by-the-collector","title":"Data Measured by the Collector","text":""},{"location":"benchmark/#llc-misses-over-time","title":"LLC Misses Over Time","text":"<p>This graph illustrates Last Level Cache (LLC) misses over a 500ms period, broken down by process. LLC misses are a key indicator of memory subsystem interference, helping identify potential noisy neighbors in the system.</p>"},{"location":"benchmark/#performance-slowdown-analysis","title":"Performance Slowdown Analysis","text":"<p>The benchmark analyzes the relationship between LLC misses and application efficiency by comparing Cycles Per Instruction (CPI) during periods of high cache contention versus normal operation:</p> <p></p> <p>This distribution shows CPI values across different levels of LLC miss activity for each process.</p> <p></p> <p>The slowdown graph quantifies the performance impact of high LLC miss rates by showing the ratio between average CPI during high cache miss periods compared to median cache miss periods. Higher values indicate greater performance degradation when cache contention occurs.</p>"},{"location":"collection/","title":"Memory Collector Telemetry Strategy","text":""},{"location":"collection/#overview","title":"Overview","text":"<p>Our telemetry strategy prioritizes high-resolution, low-level data collection to build a foundation for understanding memory subsystem interference. By focusing on simplicity and data quality in the initial collector, we can enable rapid iteration and validation of detection algorithms.</p> <p>The key aspects of our approach are:</p> <ul> <li>Collect per-process, per-core metrics at 1 millisecond granularity to capture interference at a meaningful timescale</li> <li>Collect per-process cache occupancy metrics at 1 millisecond granularity</li> <li>Generate synchronized datasets for joint analysis</li> <li>Implement in stages to manage complexity</li> </ul> <p>This \"firehose\" telemetry will enable us to build a dataset for offline analysis, allowing us to identify patterns and develop algorithms for real-time interference detection.</p>"},{"location":"collection/#telemetry-collection","title":"Telemetry Collection","text":"<p>The collector will monitor and record the following metrics for each process at 1 millisecond granularity:</p> <ul> <li>Process ID</li> <li>Core ID </li> <li>Core frequency during the measured interval</li> <li>Cycles </li> <li>Instructions</li> <li>Last level cache misses</li> </ul> <p>Modern cloud environments routinely run dozens or even hundreds of applications on a single server, each with its own dynamic memory usage patterns. In an extreme case, with 100 applications changing phase every second on average, there would be a phase change every 10 milliseconds in aggregate.</p> <p>The 1 millisecond telemetry granularity enables us to detect this behavior and characterize interference at a meaningful timescale.</p> <p>In addition to these per-process metrics, we will also collect cache occupancy measurements using Intel RDT's Cache Monitoring Technology (CMT) or an equivalent mechanism. This data will be collected per process at the same 1 millisecond granularity.</p> <p>Monitoring cache usage per process is necessary because caches maintain state across context switches and are shared by all threads of a process.</p>"},{"location":"collection/#data-format","title":"Data Format","text":"<p>For the initial version, telemetry will be written to CSV files to simplify data collection and analysis. Each row will represent a single measurement interval for a specific process.</p> <p>We will generate two datasets:</p> <ol> <li>Per-process, per-core measurements (process ID, core ID, frequency, cycles, instructions, LLC misses)</li> <li>Per-process cache occupancy measurements</li> </ol> <p>While these datasets will be separate, they will be synchronized and aligned by timestamp to enable joint analysis.</p>"},{"location":"collection/#implementation-stages","title":"Implementation Stages","text":"<p>To manage complexity, we will implement telemetry collection in two stages:</p> <ol> <li>Collect per-process, per-core measurements (process ID, core ID, frequency, cycles, instructions, LLC misses)</li> <li>Add per-process cache occupancy measurements using Intel RDT or an equivalent mechanism</li> </ol> <p>This staged approach allows us to validate the core telemetry pipeline before adding the complexity of cache monitoring.</p> <p>For the cache monitoring stage, we will need to assign each process a unique identifier (e.g., CLOS for Intel RDT) to track its cache usage. This will require additional system-level coordination and metadata management.</p>"},{"location":"collection/#analysis-and-algorithm-development","title":"Analysis and Algorithm Development","text":"<p>By collecting high-resolution telemetry from multiple clusters, both real-world deployments and benchmark environments, we aim to build a representative dataset capturing a wide range of interference scenarios.</p> <p>Analyzing this data offline using big data techniques will help us identify common interference patterns, resource usage signatures, and relevant metrics for detecting contention.</p> <p>These insights will inform the development of algorithms for real-time interference detection in future collector versions. Starting with a thorough understanding of low-level behavior is key to building effective higher-level detection and mitigation strategies.</p>"},{"location":"design/","title":"RMID Tracking Design","text":""},{"location":"design/#overview","title":"Overview","text":"<p>The RMID (Resource Monitoring ID) tracking system maintains a record of RMID allocations and deallocations in userspace, integrated with the time slot based aggregation system. The system consists of three main components:</p> <ol> <li>Kernel Module: </li> <li>Manages RMID allocation and deallocation</li> <li>Sends time-based and sched_switch based tracepoints to trigger perf measurement in eBPF</li> <li>Reads Intel RDT memory bandwidth and cache footprint metrics by RMID and sends them to eBPF</li> <li>eBPF Program:</li> <li>Relays RMID lifecycle and RDT measurements to userspace</li> <li>Reads perf measurements (cycles, instructions, etc) and sends to userspace</li> <li>Userspace Collector: Processes events and maintains RMID state</li> </ol>"},{"location":"design/#kernel-module-semantics","title":"Kernel Module Semantics","text":"<p>The kernel module provides the following guarantees for RMID management:</p> <ol> <li>RMID Allocation:</li> <li>RMIDs are allocated to thread group leaders (processes)</li> <li>All threads within a process share the same RMID</li> <li>RMID 0 is reserved and considered invalid</li> <li>Each RMID uniquely identifies a single process during any measurement window</li> <li> <p>Allocation includes process metadata (comm, tgid)</p> </li> <li> <p>RMID Lifetime:</p> </li> <li>RMIDs remain valid until explicitly freed</li> <li>RMIDs are freed when a process terminates</li> <li>After being freed, an RMID cannot be reused for at least 2ms (limbo period)</li> <li>This limbo period ensures measurement intervals (1ms) remain unambiguous</li> <li> <p>Prevents the ABA problem where measurements from different processes could be mixed</p> </li> <li> <p>RMID State:</p> </li> <li>The kernel maintains the mapping between processes and RMIDs</li> <li>RMIDs are process-specific and persist across thread creation</li> <li>RMIDs are automatically freed when a process exits</li> <li>On systems with hardware RDT support, RMIDs are programmed into MSRs</li> <li> <p>On systems without RDT support, RMIDs are emulated for consistent behavior</p> </li> <li> <p>Resource Management:</p> </li> <li>RMIDs are a limited resource (typically 512 maximum)</li> <li>Freed RMIDs are added to a FIFO queue for reuse</li> <li>The FIFO reuse policy allows cache footprints to decay before reuse</li> <li> <p>The limbo period is kept minimal (2ms) to maintain high RMID availability</p> </li> <li> <p>State Dumps</p> </li> <li>A procfs interface allows dumping current RMID assignments. </li> <li>Enables collectors to receive state of processes that existed before collector startup</li> </ol>"},{"location":"design/#message-protocol","title":"Message Protocol","text":"<p>The eBPF program communicates three types of events to userspace through a perf event array:</p> <ol> <li>Performance Measurement, including cycles, instructions, LLC misses, and time delta -- attributed to RMID</li> <li>RMID Allocation</li> <li>RMID Free</li> </ol>"},{"location":"design/#message-flow","title":"Message Flow","text":"<ol> <li>eBPF code sends all messages via a single perf event array</li> <li>Messages are enqueued in arrival time order in the per-cpu ring buffers</li> <li>Userspace processes messages from all per-cpu ring buffers in global timestamp order</li> </ol>"},{"location":"design/#userspace-rmid-package","title":"Userspace RMID Package","text":""},{"location":"design/#components","title":"Components","text":"<ol> <li><code>Metadata</code> Structure: </li> <li>Maintains metadata for each RMID</li> <li><code>Message</code> Structure: </li> <li>Holds previously received messages that have not been processed into the current state</li> <li><code>Tracker</code> Structure:</li> <li>Maintains current RMID state</li> <li>Queues updates for ordered processing</li> <li>Preserves metadata after RMID free</li> </ol>"},{"location":"design/#key-operations","title":"Key Operations","text":"<ol> <li><code>Alloc(rmid, comm, tgid, timestamp)</code>:</li> <li>Enqueues RMID allocation with metadata</li> <li> <p>Maintains timestamp order</p> </li> <li> <p><code>Free(rmid, timestamp)</code>:</p> </li> <li>Enqueues RMID free event</li> <li> <p>Maintains timestamp order</p> </li> <li> <p><code>Advance(timestamp)</code>:</p> </li> <li>Processes queued events up to timestamp</li> <li>Updates current state snapshot</li> <li>Maintains FIFO ordering of events</li> </ol>"},{"location":"design/#integration-with-time-slot-system","title":"Integration with Time Slot System","text":"<ol> <li>Time Slot Structure:</li> <li>1ms duration</li> <li>Maintains window of several slots</li> <li> <p>Retires oldest slot when window advances</p> </li> <li> <p>RMID State Management:</p> </li> <li>RMID tracker advances with each time slot retirement</li> <li>Metadata preserved after free for correct attribution</li> <li>Kernel's 2ms limbo period ensures measurement integrity</li> <li> <p>Each RMID uniquely identifies a single process during any 1ms measurement window</p> </li> <li> <p>Event Processing:</p> </li> <li>All events (perf, alloc, free) processed in timestamp order</li> <li>RMID state advanced before writing each time slot</li> <li>Measurements attributed using RMID state from appropriate time slot</li> </ol>"},{"location":"design/#metadata-preservation","title":"Metadata Preservation","text":"<p>The system preserves RMID metadata after an RMID is freed to ensure correct attribution of measurements within the same time slot. This is necessary because:</p> <ol> <li>An RMID may be freed during a time slot</li> <li>Measurements from that RMID may still arrive for the same time slot</li> <li>The metadata is needed to properly attribute these measurements</li> <li>The kernel's 2ms limbo period prevents incorrect attribution by ensuring no RMID reuse within measurement windows</li> </ol>"},{"location":"design/#error-handling","title":"Error Handling","text":"<ol> <li>Message Parsing:</li> <li>Invalid message types logged and skipped</li> <li>Malformed messages logged and skipped</li> <li> <p>Lost messages tracked and reported</p> </li> <li> <p>Time Ordering:</p> </li> <li>Messages processed strictly in timestamp order</li> <li>Safe timestamp arithmetic for overflow handling</li> <li> <p>Efficient queue management</p> </li> <li> <p>Resource Management:</p> </li> <li>Proper cleanup on shutdown</li> <li>Memory usage bounded by window size</li> <li>Efficient state tracking</li> <li>RMID allocation failures logged when no RMIDs are available that have been free long enough</li> </ol>"},{"location":"devlog/","title":"Devlog","text":"<p>Documentation of development steps, environment, and dependencies  </p> <ul> <li>Contributors: atimeofday</li> <li>Goals: Create skeleton collector with Prometheus endpoint</li> <li>Issues: https://github.com/perfpod/memory-collector/issues/19</li> </ul> <p>Initial environment and tools:</p> <pre><code># Shell: Bash\ndistrobox create --image fedora:40 --name memory-collector \ndistrobox enter memory-collector\nsudo dnf install git go\n\n# cd to preferred project directory\n# Clone (fork of) project\ngit clone https://github.com/perfpod/memory-collector\ncd memory-collector\n</code></pre> <p>Issue 19 objective 1: Create a <code>main.go</code> file in <code>cmd/collector</code></p> <pre><code>mkdir -p cmd/collector\ncd cmd/collector\ntouch main.go\n</code></pre> <ul> <li>Prometheus client_golang reference guide: https://prometheus.io/docs/guides/go-application/</li> <li>Go package installation reference: https://go.dev/doc/go-get-install-deprecation</li> <li>Go Module reference: https://go.dev/ref/mod#go-mod-init</li> <li><code>go get</code> and <code>go install</code> require a Go Module and/or @version tag as of Go 1.17 in August 2021</li> <li>Prometheus go_client installation instructions appear to be outdated and missing a piece</li> <li>Submitted issue to Prometheus documentation repository: https://github.com/prometheus/docs/issues/2556#issue-2736636166</li> <li>Proceeded with Prometheus client_golang guide </li> </ul> <pre><code>cd cmd/collector\ngo mod init memory-collector\ngo get github.com/prometheus/client_golang/prometheus\ngo get github.com/prometheus/client_golang/prometheus/promauto\ngo get github.com/prometheus/client_golang/prometheus/promhttp\n</code></pre> <p>Issue 19 objective 2: Expose an endpoint on a known fixed port </p> <pre><code># Wrote and tested example Go exposition application from Prometheus guide\ngo run main.go &amp;\ncurl http://localhost:2112/metrics\n</code></pre> <p>Issue 19 objective 3: Expose the <code>up</code> metric with value 1</p> <pre><code>// Created, registered, and set an 'up' metric in func main()\n\nupMetric := prometheus.NewGauge(prometheus.GaugeOpts{\n    Namespace:  \"perfpod\",\n    Subsystem:  \"memory_collector\",\n    Name:       \"up_metric\",\n    Help:       \"Test metric to confirm skeleton application functionality.\",\n})\nprometheus.MustRegister(upMetric)\n\nupMetric.Set(1)\n</code></pre> <p>Issue 19 objective 4: Manually verify: query the endpoint using <code>curl</code> or <code>wget</code></p> <pre><code>curl -s http://localhost:2112/metrics | grep up_metric\n</code></pre> <p>Output:</p> <pre><code># HELP perfpod_memory_collector_up_metric Test metric to confirm skeleton application functionality.\n# TYPE perfpod_memory_collector_up_metric gauge\nperfpod_memory_collector_up_metric 1\n</code></pre> <p>Issue 19 objective 5: Move the code into a function (not <code>main()</code>)</p> <pre><code>// Moved Up metric into \"func recordMetrics()\" and added function call in main()\n\nfunc main() {\n    recordMetrics()\n\n    http.Handle(\"/metrics\", promhttp.Handler())\n    http.ListenAndServe(\":2112\", nil)\n}\n\n// Repeated manual verification endpoint query\n</code></pre> <p>Issue 19 objective 6: Add an integration test that verifies the metrics are up, using client_golang's testutil - TO DO - May require assistance</p> <ul> <li>Issue 19 split into 5/5 done and new Issue 20</li> <li>Issue 19 5/5 PR opened and merged</li> </ul> <ul> <li>Contributors: atimeofday</li> <li>Goals: Add integration test to Prometheus endpoint</li> <li>Issues: https://github.com/perfpod/memory-collector/issues/20</li> </ul> <p>Research &amp; references:</p> <pre><code>https://go.dev/doc/tutorial/add-a-test\nhttps://albertmoreno.dev/posts/testing-prometheus-metrics-in-integration-tests-in-golang/\nhttps://github.com/prometheus/client_golang/blob/main/prometheus/testutil/testutil.go\nhttps://github.com/prometheus/client_golang/blob/main/prometheus/testutil/testutil_test.go\n</code></pre> <pre><code>go get github.com/prometheus/client_golang/prometheus/testutil \ngo get github.com/stretchr/testify/require\n</code></pre> <p>Go test format:</p> <pre><code>[filename]_test.go\n\nimport(\n    [...]\n)\n\nfunc [TestFunction](t *testing.T) {\n    // Set test values\n    // Perform test\n}\n\n// Perform more tests\n</code></pre> <ol> <li>Created skeleton test based on examples </li> </ol> <pre><code>func TestMetricsUp(t *testing.T) {\n    require.Eventuallyf(t, func() bool {\n\n        // Test values\n        // ??? expected format\n\n        if err := testutil.ScrapeAndCompare(serverURL+\"/metrics\", strings.NewReader(expected), metricName); err == nil {\n            return true\n        } else {\n            t.Log(err.Error())\n            return false\n        }\n    }, time.Second, 100*time.Millisecond, \"Could not find metric %s with value %d\", metricName, expectedMetricValue)\n}\n</code></pre> <ol> <li>Checked the implementation of the testutil ScrapeAndCompare function, and notably, the implementation of its own integration test.</li> <li>Located and implemented the exact input template required by the function, then implemented generalized code for the template.</li> <li>Researched goroutines to allow automatically initializing the (currently local) remote server to be tested.</li> </ol> <pre><code>go main()\ntime.Sleep(1 * time.Second)\n</code></pre> <ol> <li>Refined logical flow from example code for improved readability.</li> </ol> <ul> <li>Issue 20 done</li> </ul> <ul> <li>Contributors: </li> <li>Goals: </li> <li>Issues: </li> </ul>"},{"location":"noise-generators/","title":"Synthetic Noise Generators","text":"<p>Synthetic noise generators are programs that cause noisy-neighbor stress on shared resources. In our case, this would be memory bandwidth and cache.</p> <p>Noise generators can be used for: 1. Testing that metrics the collector outputs are correct 2. When used in a cluster running a multi-service workload like microservices-demo, shows how the services behave under noisy neighbor. 3. Can potentially be used in staging environments to get an indication how a company's real workload would behave under noisy neighbor.</p>"},{"location":"noise-generators/#conclusion","title":"Conclusion","text":"<p>Intel MLC is the best fit, given its wide configurability via the command line, and extensive documentation. The shortcoming is that it is not open source. Installing it requires accepting the license, which might be hard automatically from a CI system, so might require some investment in automation.</p>"},{"location":"noise-generators/#top-contenders","title":"Top contenders","text":""},{"location":"noise-generators/#intel-memory-latency-checker-intel-mlc","title":"Intel Memory Latency Checker (Intel MLC)","text":"<p>Binary distribution (does not seem to be OSS). Is able to gather multiple baselines: - Idle latency and maximum bandwidth, for each source and destination NUMA node - Peak memory bandwidth at different read-write ratios - Latencies under different bandwidth loads</p> <p>The binary also disables prefetches for the duration of the run for more accurate results.</p> <ul> <li>It is possible to select the delay between memory accesses in the bandwidth generators (<code>-d</code> parameter)</li> <li>Can specify array sizes for bandwidth generation (<code>-b</code>)</li> <li>A latency-measurement thread generates dependent accesses, it might be reusable to measure a histogram of latencies on a live system (without generating bandwidth noise), would need further investigation. The idle_latency mode might do exactly that.</li> <li>Control what CPUs allocate memory, and where latency measurements run. (<code>-i</code>, <code>-j</code>)</li> <li>Can specify which CPUs are used for bandwidth measurement (<code>-k</code>)</li> <li>Ensures entire CPUs are not put in lower frequency because all cores are idle by 100% utilizing a core on each CPU (<code>-p</code>)</li> <li>In AVX512, can request explicit flushing of cache lines to DRAM (<code>-P</code>, <code>-Q</code>)</li> <li>There is an L3 bandwidth measurement mode that tests just the bandwidth to read from L3 (<code>-u</code>)</li> <li>Controlling random vs sequential access, both in latency-measurement threads and bandwidth-generation threads</li> <li>Read to write ratio (<code>-W</code>, <code>-R</code>)</li> </ul>"},{"location":"noise-generators/#pmbw-github","title":"pmbw (GitHub)","text":"<p>A C/C++ noise generator for cache and RAM, with the access loops coded in assembly. Tests have several configuration options, to achieve different stress patterns: - Sequential scanning versus walking permutations - Read or Write - Number of bits transferred per instruction, from 16 up to 256 via SSE/MMX/AVX - Accessing components using pointers versus index-accessing arrays - Regular tests, or tests with unrolled loop (I assume, to stress the instruction cache or to avoid branches on every iteration)</p> <p>Appears relatively easy to compile, since it only requires the <code>pthreads</code> and <code>rt</code> libraries.</p>"},{"location":"noise-generators/#also-considered","title":"Also considered","text":""},{"location":"noise-generators/#sysbench","title":"Sysbench","text":"<p>Mentions it is mostly used for database benchmarks, but its README mentions <code>memory</code>, a memory access benchmark. The README also documents general purpose command line parameters like the number of threads and warmup time, but a quick scan did not generate more documentation for the <code>memory</code> benchmarks.</p> <p>We found it less likely to be a fit, given its database focus and lack of documentation for the memory benchmark.</p>"},{"location":"noise-generators/#stream","title":"STREAM","text":"<p>Mature package, earliest submissions from 1991 (latest update to website benchmark 2017). Seems to be a single C and single FORTRAN source file, with a Makefile. There is very little control over the measured pattern and results are very concise: main tuning point is the size of array being measured <code>STREAM_ARRAY_SIZE</code>, and results are printed with:</p> <pre><code>    printf(\"Function    Best Rate MB/s  Avg time     Min time     Max time\\n\");\n</code></pre> <p>A recent Intel mention shows how to compile an optimized version of STREAM.</p> <p>STREAM was used in the Themis paper.</p> <p>We found it less likely to be a fit, given its lack of control over the stress pattern and results.</p>"},{"location":"noise-generators/#mmatyasbandwidth-benchmark","title":"mmatyas/bandwidth-benchmark","text":"<p>This is a memory and network bandwidth benchmark. The source code indicates development 2005-2016, with many versions, but there is little activity on GitHub. Supports SSE/AVX and random access. Earlier tests run 5 second tests for a total of 35 minutes. CSV output.</p> <p>This could be a fit, but has less documentation than the alternatives.</p>"},{"location":"noise-generators/#cachebench","title":"Cachebench","text":"<p>While used in Alita as LLC polluter, the program seems to have been developed in 1998 at University of Tennessee at Knoxville and the repo has not received additional contributions since. It has a README and pdf guide.</p>"},{"location":"noise-generators/#ibench","title":"iBench","text":"<p>Appears to have been used in multiple papers Paragon, Seer, Quasar, FIRM (alongside <code>pmbw</code>), and PARTIES. It is described in a paper.</p> <p>The repo appears to contain just 7 of the 15 stressors described in the iBench paper. Its memory bandwidth stressor seems to be less extensive than the memory access functions in <code>pmbw</code> (e.g., 860 lines of code in funcs_x86_64.g vs. 87 lines in memBw.c). The memory bandwidth benchmark only receives the length of the benchmark as a parameter, and it is unclear how to adjust the stress intensity.</p>"},{"location":"pipeline-implementation/","title":"Pipeline Implementation Guide","text":"<p>This document describes how the collector implements streaming data pipelines using Rust's async ecosystem, focusing on channel communication, error handling, and graceful shutdown patterns.</p>"},{"location":"pipeline-implementation/#channel-communication-patterns","title":"Channel Communication Patterns","text":""},{"location":"pipeline-implementation/#channel-types-and-creation","title":"Channel Types and Creation","text":"<p>The pipeline creates and configures all channels, transferring them to individual stages rather than having stages create their own channels. The pipeline drops its references to senders so that receiver stages can detect when all senders are closed, and transfers receiver ownership to the consuming stages.</p> <p>Bounded channels provide the foundation for backpressure-aware streaming pipelines. We use bounded channels to prevent memory exhaustion under high load conditions, with the channel itself serving as the buffer mechanism.</p>"},{"location":"pipeline-implementation/#mpsc-channels-for-pipeline-connectivity","title":"MPSC Channels for Pipeline Connectivity","text":"<p>MPSC (Multi-Producer, Single-Consumer) channels are our primary choice for connecting pipeline stages. While we typically use single producers, MPSC is the standard Tokio implementation we rely on. For system measurement data, we typically use a capacity of 1000-10000 messages based on data frequency and processing latency requirements.</p>"},{"location":"pipeline-implementation/#backpressure-handling","title":"Backpressure Handling","text":"<p>Backpressure handling becomes critical when processing high-frequency eBPF measurements. Our strategy focuses on time slot dropping with logging:</p> <ul> <li>Drop time slots when downstream stages cannot keep up</li> <li>Log the number of dropped time slots and report counts every second</li> <li>Avoid blocking to ensure forward progress</li> </ul>"},{"location":"pipeline-implementation/#rate-limited-console-logging","title":"Rate-Limited Console Logging","text":"<p>Since we process thousands of time slots per second, we need rate limiting mechanisms to avoid console spam. The pattern is for each processing loop to maintain its own drop counter and use <code>tokio::select!</code> with a timer for periodic logging.</p> <pre><code>use tokio::time::{interval, Duration};\n\nasync fn processing_loop_with_drop_logging(\n    mut input_rx: mpsc::Receiver&lt;TimeslotData&gt;,\n    output_tx: mpsc::Sender&lt;ProcessedData&gt;,\n) -&gt; Result&lt;(), ProcessingError&gt; {\n    let mut drop_count = 0u64;\n    let mut log_timer = interval(Duration::from_secs(1));\n\n    loop {\n        tokio::select! {\n            result = input_rx.recv() =&gt; {\n                match result {\n                    Some(timeslot) =&gt; {\n                        let processed = process_timeslot(timeslot).await?;\n\n                        // Try to send without blocking\n                        match output_tx.try_send(processed) {\n                            Ok(_) =&gt; {\n                                // Successfully sent\n                            }\n                            Err(mpsc::error::TrySendError::Full(_)) =&gt; {\n                                // Channel full - drop time slot\n                                drop_count += 1;\n                                metrics::counter!(\"timeslots_dropped\").increment(1);\n                            }\n                            Err(mpsc::error::TrySendError::Closed(_)) =&gt; {\n                                // Receiver dropped - pipeline shutting down\n                                break;\n                            }\n                        }\n                    }\n                    None =&gt; {\n                        // Input channel closed - pipeline shutting down\n                        break;\n                    }\n                }\n            }\n\n            _ = log_timer.tick() =&gt; {\n                // Log drops every second\n                if drop_count &gt; 0 {\n                    log::warn!(\"Dropped {} time slots in last second\", drop_count);\n                    drop_count = 0;\n                }\n            }\n        }\n    }\n\n    Ok(())\n}\n</code></pre>"},{"location":"pipeline-implementation/#error-handling-and-supervision","title":"Error Handling and Supervision","text":""},{"location":"pipeline-implementation/#error-coordination-with-supervision-tasks","title":"Error Coordination with Supervision Tasks","text":"<p>Error channels communicate failures to monitoring and supervision tasks rather than between processing stages directly. Each pipeline stage receives an error sender to report failures to a centralized monitoring task.</p> <pre><code>use tokio_util::sync::CancellationToken;\nuse tokio::sync::mpsc;\n\nstruct PipelineStage {\n    error_tx: mpsc::UnboundedSender&lt;PipelineError&gt;,\n    shutdown_token: CancellationToken,\n}\n\nimpl PipelineStage {\n    async fn run(&amp;self) -&gt; Result&lt;(), PipelineError&gt; {\n        let shutdown_token = self.shutdown_token.clone();\n\n        tokio::select! {\n            _ = shutdown_token.cancelled() =&gt; {\n                tracing::info!(\"Stage shutting down gracefully\");\n                Ok(())\n            }\n            result = self.execute_stage_logic() =&gt; {\n                match result {\n                    Ok(_) =&gt; Ok(()),\n                    Err(e) =&gt; {\n                        tracing::error!(\"Stage failed: {:?}\", e);\n                        self.error_tx.send(e.clone()).ok();\n                        Err(e)\n                    }\n                }\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"pipeline-implementation/#error-handling-strategy","title":"Error Handling Strategy","text":"<p>Errors in our system tend to be fatal. Rather than implementing complex restart strategies, we:</p> <ul> <li>Report errors to the supervision task</li> <li>Supervision task triggers graceful shutdown with timeout</li> <li>Force shutdown if graceful shutdown timeout expires</li> <li>Allow the collector pod to restart after shutdown</li> <li>Log comprehensive error information for debugging</li> </ul> <p>Unlike signal-based shutdown where we can rely on Kubernetes' grace period, error-triggered shutdowns require their own timeout mechanism since Kubernetes isn't initiating the shutdown.</p> <pre><code>use tokio::time::{timeout, Duration};\n\nasync fn supervision_task(\n    mut error_rx: mpsc::UnboundedReceiver&lt;PipelineError&gt;,\n    shutdown_token: CancellationToken,\n    graceful_shutdown_timeout: Duration,\n) -&gt; Result&lt;(), SupervisionError&gt; {\n    while let Some(error) = error_rx.recv().await {\n        tracing::error!(\"Pipeline error received: {:?}\", error);\n\n        // Trigger graceful shutdown\n        tracing::info!(\"Initiating graceful shutdown due to error\");\n        shutdown_token.cancel();\n\n        // Wait for graceful shutdown with timeout\n        match timeout(graceful_shutdown_timeout, wait_for_pipeline_shutdown()).await {\n            Ok(_) =&gt; {\n                tracing::info!(\"Graceful shutdown completed successfully\");\n                break;\n            }\n            Err(_) =&gt; {\n                tracing::error!(\"Graceful shutdown timeout expired, forcing shutdown\");\n                // Force shutdown mechanisms here (e.g., std::process::exit)\n                std::process::exit(1);\n            }\n        }\n    }\n\n    Ok(())\n}\n</code></pre> <p>This approach attempts graceful shutdown first with a reasonable timeout, then falls back to forced shutdown to prevent hanging on fatal errors.</p>"},{"location":"pipeline-implementation/#graceful-shutdown-patterns","title":"Graceful Shutdown Patterns","text":""},{"location":"pipeline-implementation/#shutdown-coordination-strategy","title":"Shutdown Coordination Strategy","text":"<p>Cancellation tokens coordinate shutdown across pipeline stages. However, stages that only read from channels don't need to monitor the cancellation token directly\u2014they should drain their inputs until no more data is available, then close their outputs and terminate.</p> <p>Only stages that don't follow this pattern need explicit shutdown signaling, such as stages reading from eBPF rings that need to stop reading and perform cleanup.</p> <pre><code>use tokio::signal;\nuse tokio_util::sync::CancellationToken;\n\nasync fn channel_draining_stage(\n    mut input_rx: mpsc::Receiver&lt;MeasurementData&gt;,\n    output_tx: mpsc::Sender&lt;ProcessedData&gt;,\n) -&gt; Result&lt;(), ProcessingError&gt; {\n    // Drain input until channel closes\n    while let Some(measurement) = input_rx.recv().await {\n        let processed = process_measurement(measurement).await?;\n\n        // If output channel is closed, we're shutting down\n        if output_tx.send(processed).await.is_err() {\n            break;\n        }\n    }\n\n    // Close output channel to signal downstream stages\n    drop(output_tx);\n    Ok(())\n}\n\nasync fn ebpf_reading_stage(\n    shutdown_token: CancellationToken,\n    output_tx: mpsc::Sender&lt;MeasurementData&gt;,\n) -&gt; Result&lt;(), ProcessingError&gt; {\n    let mut ebpf_reader = EbpfReader::new().await?;\n\n    tokio::select! {\n        _ = shutdown_token.cancelled() =&gt; {\n            tracing::info!(\"eBPF stage shutting down\");\n            ebpf_reader.cleanup().await?;\n            drop(output_tx);\n            Ok(())\n        }\n        result = ebpf_reader.read_loop(&amp;output_tx) =&gt; {\n            result\n        }\n    }\n}\n</code></pre>"},{"location":"pipeline-implementation/#signal-handling","title":"Signal Handling","text":"<p>Signal handling with proper cleanup coordination ensures data integrity during system shutdown. We use an isolated signal monitor task that listens for shutdown signals and coordinates with the cancellation token.</p> <pre><code>use tokio::signal;\nuse tokio_util::sync::CancellationToken;\n\nstruct ProductionPipeline {\n    shutdown_token: CancellationToken,\n}\n\nimpl ProductionPipeline {\n    async fn spawn_signal_monitor(&amp;self) {\n        let shutdown_token = self.shutdown_token.clone();\n\n        tokio::spawn(async move {\n            let mut sigterm = signal::unix::signal(signal::unix::SignalKind::terminate()).unwrap();\n            let mut sigint = signal::unix::signal(signal::unix::SignalKind::interrupt()).unwrap();\n\n            tokio::select! {\n                _ = sigterm.recv() =&gt; {\n                    tracing::info!(\"Received SIGTERM, initiating graceful shutdown\");\n                    shutdown_token.cancel();\n                }\n                _ = sigint.recv() =&gt; {\n                    tracing::info!(\"Received SIGINT, initiating graceful shutdown\");\n                    shutdown_token.cancel();\n                }\n                _ = shutdown_token.cancelled() =&gt; {\n                    tracing::info!(\"Shutdown token cancelled, signal monitor terminating\");\n                }\n            }\n        });\n    }\n\n    async fn run_pipeline(&amp;self) -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {\n        // Start signal monitoring\n        self.spawn_signal_monitor().await;\n\n        // Start pipeline stages\n        self.start_all_stages().await?;\n\n        // Wait for shutdown signal\n        self.shutdown_token.cancelled().await;\n\n        // Initiate graceful shutdown\n        self.graceful_shutdown().await?;\n\n        Ok(())\n    }\n\n    async fn graceful_shutdown(&amp;self) -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {\n        tracing::info!(\"Initiating graceful shutdown...\");\n\n        // Signal shutdown to stages that need explicit notification\n        self.shutdown_token.cancel();\n\n        // Wait for all stages to complete (no timeout - let Kubernetes handle this)\n        self.wait_for_all_stages().await?;\n\n        tracing::info!(\"Graceful shutdown complete\");\n        Ok(())\n    }\n}\n</code></pre>"},{"location":"pipeline-implementation/#key-design-principles","title":"Key Design Principles","text":"<ol> <li>Pipeline creates channels: Stages receive pre-configured channels rather than creating their own</li> <li>Bounded channels prevent memory exhaustion: Use appropriate buffer sizes based on data frequency</li> <li>Drop time slots under backpressure: Maintain forward progress with rate-limited logging</li> <li>Cascade shutdowns through channel closure: Most stages can shut down by draining inputs</li> <li>Explicit shutdown signaling only when needed: Reserve cancellation tokens for stages that require cleanup</li> <li>Leverage Kubernetes grace periods: Allow natural shutdown timing rather than imposing artificial timeouts</li> <li>Isolated signal monitoring: Use dedicated task for signal handling with cancellation token coordination</li> </ol> <p>This architecture provides robust, high-performance streaming pipelines that handle millions of measurements per second while maintaining operational reliability and clear error reporting.</p>"},{"location":"resctrl-guide/","title":"Linux Resource Control (resctrl) Operations Guide","text":"<p>This guide documents our tested implementation of Linux Resource Control (resctrl) for Intel RDT (Resource Director Technology) monitoring and allocation. The examples are based on our validated GitHub Actions workflow that demonstrates practical resource control with real workloads.</p>"},{"location":"resctrl-guide/#important-note-resctrl-vs-cgroup","title":"Important Note: resctrl vs cgroup","text":"<p>This guide focuses on Intel RDT/resctrl (<code>/sys/fs/resctrl</code>), which provides hardware-level resource control using Intel RDT features like Cache Allocation Technology (CAT), Memory Bandwidth Allocation (MBA), and Cache Monitoring Technology (CMT). This is different from cgroup resource control (<code>/sys/fs/cgroup</code>), which provides software-level scheduling controls.</p> <p>For comprehensive cgroup v2 resource control, see the Facebook resctl-demo project, which demonstrates cgroup-based resource protection and memory management.</p>"},{"location":"resctrl-guide/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Hardware Requirements and Setup</li> <li>Our Tested Implementation</li> <li>Resource Control Workflow</li> <li>Measurement and Monitoring</li> <li>Untested Capabilities</li> <li>References</li> </ol>"},{"location":"resctrl-guide/#hardware-requirements-and-setup","title":"Hardware Requirements and Setup","text":""},{"location":"resctrl-guide/#verify-hardware-support","title":"Verify Hardware Support","text":"<pre><code># Check CPU features for RDT support\ngrep -E \"rdt_a|cat_l3|cqm_llc|cqm_occup_llc|cqm_mbm_total|cqm_mbm_local|mba\" /proc/cpuinfo\n\n# Check kernel support\ncat /proc/filesystems | grep resctrl\n</code></pre>"},{"location":"resctrl-guide/#mount-resctrl-filesystem","title":"Mount resctrl Filesystem","text":"<pre><code># Mount resctrl filesystem (basic mount we use)\nsudo mkdir -p /sys/fs/resctrl\nsudo mount -t resctrl resctrl /sys/fs/resctrl\n\n# Verify mount\nmount | grep resctrl\n</code></pre>"},{"location":"resctrl-guide/#check-available-capabilities","title":"Check Available Capabilities","text":"<pre><code># Hardware capabilities we actually use\necho \"CLOSIDs: $(cat /sys/fs/resctrl/info/L3/num_closids)\"\necho \"RMIDs: $(cat /sys/fs/resctrl/info/L3_MON/num_rmids)\"\necho \"Cache mask: $(cat /sys/fs/resctrl/info/L3/cbm_mask)\"\necho \"Min bandwidth: $(cat /sys/fs/resctrl/info/MB/min_bandwidth)%\"\n</code></pre>"},{"location":"resctrl-guide/#our-tested-implementation","title":"Our Tested Implementation","text":""},{"location":"resctrl-guide/#workload-design","title":"Workload Design","text":"<p>Our implementation demonstrates resource control using two distinct workload types:</p> <ol> <li>Memory Bandwidth Intensive: Uses <code>stress-ng --vm X --vm-bytes 75%</code> to create high memory bandwidth demand</li> <li>Cache Sensitive: Uses <code>stress-ng --cache X --cache-size XM --perf --metrics-brief</code> to create measurable cache performance patterns</li> </ol>"},{"location":"resctrl-guide/#resource-group-creation","title":"Resource Group Creation","text":"<pre><code># Create two resource control groups (our tested approach)\nsudo mkdir -p /sys/fs/resctrl/memory_bandwidth_group\nsudo mkdir -p /sys/fs/resctrl/cache_sensitive_group\n\n# CPU assignment strategy: quarters of total CPUs for isolation\n# Memory bandwidth group gets first quarter (CPUs 0 to N/4-1)\n# Cache sensitive group gets second quarter (CPUs N/4 to N/2-1)\n# Remaining CPUs left unassigned for isolation\n</code></pre>"},{"location":"resctrl-guide/#stress-testing-configuration","title":"Stress Testing Configuration","text":"<p>Memory Bandwidth Workload: - Command: <code>stress-ng --vm [threads] --vm-bytes 75%</code> - Thread count: Half of assigned CPU quarter (1/8 of total system CPUs) - Duration: Long-running (30 minutes) to maintain consistent memory pressure</p> <p>Cache Sensitive Workload: - Command: <code>stress-ng --cache [threads] --cache-size [size]M --perf --metrics-brief</code> - Thread count: 1/8 of assigned CPU quarter - Cache size: 1MB per assigned CPU, distributed across threads - Duration: 17 seconds with 10s warmup + 5s measurement + 2s buffer</p>"},{"location":"resctrl-guide/#resource-control-workflow","title":"Resource Control Workflow","text":"<p>Our tested workflow demonstrates five phases of resource control:</p>"},{"location":"resctrl-guide/#phase-1-baseline-cache-performance","title":"Phase 1: Baseline Cache Performance","text":"<ul> <li>Objective: Measure cache workload performance without memory bandwidth contention</li> <li>Configuration: Cache workload only, no memory bandwidth stress</li> <li>Measurements: Cache references, misses, hit rates, LLC occupancy</li> </ul>"},{"location":"resctrl-guide/#phase-2-both-workloads-unthrottled","title":"Phase 2: Both Workloads Unthrottled","text":"<ul> <li>Objective: Demonstrate resource contention without controls</li> <li>Configuration: Both workloads running with full resource access</li> <li>Expected Result: Cache performance degradation due to memory bandwidth interference</li> </ul>"},{"location":"resctrl-guide/#phase-3-memory-bandwidth-throttling","title":"Phase 3: Memory Bandwidth Throttling","text":"<ul> <li>Objective: Demonstrate Memory Bandwidth Allocation (MBA)</li> <li>Configuration: Memory bandwidth limited to 20% via schemata</li> <li>Implementation: Careful modification preserving existing L3 settings</li> </ul>"},{"location":"resctrl-guide/#phase-4-combined-memory-and-cache-restrictions","title":"Phase 4: Combined Memory and Cache Restrictions","text":"<ul> <li>Objective: Demonstrate Cache Allocation Technology (CAT) with MBA</li> <li>Configuration: Memory at 20% + cache restricted to first 4 ways</li> <li>Implementation: Careful modification preserving existing MB settings</li> </ul>"},{"location":"resctrl-guide/#phase-5-resource-restoration","title":"Phase 5: Resource Restoration","text":"<ul> <li>Objective: Verify performance recovery when restrictions are removed</li> <li>Configuration: Restore full resources to both groups</li> <li>Expected Result: Cache performance returns to near-baseline levels</li> </ul>"},{"location":"resctrl-guide/#careful-schemata-modification","title":"Careful Schemata Modification","text":"<p>Our implementation takes a conservative approach when modifying resource allocations: we read the existing schemata, modify only the specific resource line we need to change, and write it back. This preserves existing settings and prevents accidentally overwriting other resource allocations during phase transitions, however we did not check if this was strictly necessary.</p>"},{"location":"resctrl-guide/#measurement-and-monitoring","title":"Measurement and Monitoring","text":""},{"location":"resctrl-guide/#key-metrics-we-collect","title":"Key Metrics We Collect","text":"<p>Memory Bandwidth Monitoring: - <code>mbm_total_bytes</code>: Total memory bandwidth (cumulative) - <code>mbm_local_bytes</code>: Local memory bandwidth (cumulative) - Calculated rates: <code>(final_value - initial_value) / measurement_duration</code></p> <p>Cache Performance Monitoring: - <code>llc_occupancy</code>: Last Level Cache occupancy in bytes - Cache references (total LLC accesses) and misses from <code>stress-ng --perf</code> - Cache hit rate: <code>(references - misses) / references * 100</code> - Throughput: <code>stress-ng</code> bogo operations per second</p> <p>Note on Cache Counters: Per Intel SDM, LLC references and misses may include speculation and L1 hardware prefetcher activity, but may exclude other hardware prefetchers. Value comparison for performance estimation across different systems is not recommended due to implementation-specific characteristics.</p> <p>Data Collection Format:</p> <pre><code>phase,workload_type,llc_occupancy,memory_bandwidth_total,memory_bandwidth_local,cache_references_gbps,cache_misses_gbps,cache_hit_rate,bogo_ops\n</code></pre>"},{"location":"resctrl-guide/#monitoring-file-locations","title":"Monitoring File Locations","text":"<pre><code># LLC occupancy for each group\n/sys/fs/resctrl/[group_name]/mon_data/mon_L3_00/llc_occupancy\n\n# Memory bandwidth counters\n/sys/fs/resctrl/[group_name]/mon_data/mon_L3_00/mbm_total_bytes\n/sys/fs/resctrl/[group_name]/mon_data/mon_L3_00/mbm_local_bytes\n\n# Resource allocation settings\n/sys/fs/resctrl/[group_name]/schemata\n</code></pre>"},{"location":"resctrl-guide/#untested-capabilities","title":"Untested Capabilities","text":"<p>resctrl supports additional features we haven't tested:</p>"},{"location":"resctrl-guide/#mount-options-considered-but-not-tested","title":"Mount Options (Considered but Not Tested)","text":"<ul> <li><code>cdp,cdpl2</code>: Code/Data Prioritization for L3 and L2 caches</li> <li><code>mba_MBps</code>: Memory bandwidth allocation in MBps instead of percentage</li> </ul>"},{"location":"resctrl-guide/#advanced-monitoring-available-but-not-implemented","title":"Advanced Monitoring (Available but Not Implemented)","text":"<ul> <li>Monitoring subgroups: <code>mon_groups/</code> for finer-grained RMID allocation</li> <li>Multi-domain systems: Our implementation assumes single domain (domain 0)</li> <li>L2 cache monitoring: Focus was on L3 cache allocation and monitoring</li> </ul>"},{"location":"resctrl-guide/#alternative-stress-testing-approaches-considered","title":"Alternative Stress Testing Approaches (Considered)","text":"<p>Other <code>stress-ng</code> options like <code>--matrix</code>, <code>--stream</code>, and <code>--cpu</code> methods could provide different stress patterns but weren't necessary for our demonstration.</p>"},{"location":"resctrl-guide/#programming-interface-available-but-not-used","title":"Programming Interface (Available but Not Used)","text":"<p>Tools like intel-cmt-cat provide C/C++ APIs for resctrl operations. Our shell-based approach was sufficient for demonstration purposes.</p>"},{"location":"resctrl-guide/#references","title":"References","text":""},{"location":"resctrl-guide/#workflow-implementation","title":"Workflow Implementation","text":"<ul> <li>GitHub Actions Workflow: <code>.github/workflows/resctrl-demo.yaml</code> - Complete tested implementation</li> </ul>"},{"location":"resctrl-guide/#related-projects-and-documentation","title":"Related Projects and Documentation","text":"<ul> <li>Linux Kernel Documentation: resctrl.rst</li> <li>Facebook resctl-demo: GitHub Repository - Comprehensive cgroup-based resource control (different from resctrl)</li> <li>Intel RDT Tools: intel-cmt-cat - Intel's official RDT user-space tools</li> <li>stress-ng Documentation: Ubuntu stress-ng Reference</li> </ul>"},{"location":"s3-testing/","title":"S3 Testing for Memory Collector","text":"<p>This document explains how to set up and run the S3 integration tests for the memory collector.</p>"},{"location":"s3-testing/#bucket-setup","title":"Bucket Setup","text":"<p>The tests require two S3 buckets with different authentication methods:</p> <ol> <li>IRSA Bucket (<code>unvariance-collector-test-irsa</code>): Uses IAM role-based authentication</li> <li>Key-Auth Bucket (<code>unvariance-collector-test-key-auth</code>): Uses access key authentication</li> </ol>"},{"location":"s3-testing/#creating-the-buckets","title":"Creating the Buckets","text":"<p>Run these commands to create the buckets (adjust region as needed):</p> <pre><code>aws s3api create-bucket --bucket unvariance-collector-test-irsa --region us-east-2 --create-bucket-configuration LocationConstraint=us-east-2\naws s3api create-bucket --bucket unvariance-collector-test-key-auth --region us-east-2 --create-bucket-configuration LocationConstraint=us-east-2\n</code></pre>"},{"location":"s3-testing/#setting-up-lifecycle-policies","title":"Setting Up Lifecycle Policies","text":"<p>To avoid accumulating test data and control costs, set up lifecycle policies to delete objects after 1 day:</p> <pre><code># Create lifecycle policy JSON\ncat &gt; lifecycle-policy.json &lt;&lt; EOF\n{\n  \"Rules\": [\n    {\n      \"ID\": \"DeleteAfterOneDay\",\n      \"Status\": \"Enabled\",\n      \"Prefix\": \"\",\n      \"Expiration\": {\n        \"Days\": 1\n      }\n    }\n  ]\n}\nEOF\n\n# Apply to both buckets\naws s3api put-bucket-lifecycle-configuration --bucket unvariance-collector-test-irsa --lifecycle-configuration file://lifecycle-policy.json\naws s3api put-bucket-lifecycle-configuration --bucket unvariance-collector-test-key-auth --lifecycle-configuration file://lifecycle-policy.json\n</code></pre>"},{"location":"s3-testing/#iam-permissions-setup","title":"IAM Permissions Setup","text":""},{"location":"s3-testing/#irsa-bucket-permissions","title":"IRSA Bucket Permissions","text":"<p>The IAM role used by the GitHub Actions runner needs permissions to write to the IRSA bucket. Add this policy to the role:</p> <pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"s3:PutObject\",\n        \"s3:GetObject\",\n        \"s3:ListBucket\",\n        \"s3:DeleteObject\",\n        \"s3:AbortMultipartUpload\",\n        \"s3:ListMultipartUploadParts\",\n        \"s3:ListBucketMultipartUploads\"\n      ],\n      \"Resource\": [\n        \"arn:aws:s3:::unvariance-collector-test-irsa\",\n        \"arn:aws:s3:::unvariance-collector-test-irsa/*\"\n      ]\n    }\n  ]\n}\n</code></pre>"},{"location":"s3-testing/#access-key-authentication","title":"Access Key Authentication","text":"<p>For the key-auth bucket, create a dedicated IAM user with limited permissions:</p> <ol> <li>Create an IAM user (e.g., <code>collector-test-user</code>)</li> <li>Attach this policy to the user:</li> </ol> <pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"s3:PutObject\",\n        \"s3:GetObject\",\n        \"s3:ListBucket\",\n        \"s3:DeleteObject\",\n        \"s3:AbortMultipartUpload\",\n        \"s3:ListMultipartUploadParts\",\n        \"s3:ListBucketMultipartUploads\"\n      ],\n      \"Resource\": [\n        \"arn:aws:s3:::unvariance-collector-test-key-auth\",\n        \"arn:aws:s3:::unvariance-collector-test-key-auth/*\"\n      ]\n    }\n  ]\n}\n</code></pre> <ol> <li>Generate access keys for this user</li> <li>Add the keys to GitHub repository secrets:</li> <li><code>S3_ACCESS_KEY_ID</code>: The access key ID</li> <li><code>S3_SECRET_ACCESS_KEY</code>: The secret access key</li> </ol>"},{"location":"s3-testing/#running-the-tests-manually","title":"Running the Tests Manually","text":"<p>To run the S3 tests manually:</p> <ol> <li>Go to the GitHub repository</li> <li>Navigate to the \"Actions\" tab</li> <li>Select the \"test-ebpf-collector\" workflow</li> <li>Click \"Run workflow\"</li> <li>Use the default settings or customize the EC2 instance type</li> <li>Click \"Run workflow\"</li> </ol>"},{"location":"s3-testing/#test-workflow-explanation","title":"Test Workflow Explanation","text":"<p>The S3 test workflow:</p> <ol> <li>Creates unique UUIDs for each test run to isolate test data</li> <li>Tests writing to S3 using IAM role authentication</li> <li>Tests writing to S3 using access key authentication</li> <li>Downloads the generated Parquet files</li> <li>Validates the file structure using PQRS</li> <li>Uploads the test files as artifacts for inspection</li> </ol>"},{"location":"s3-testing/#troubleshooting","title":"Troubleshooting","text":"<p>Common issues and solutions:</p> <ul> <li>Permission Denied: Check IAM role permissions or access key permissions, especially for multi-part upload operations</li> <li>No Files Found: Verify collector is writing files correctly and paths are correct</li> <li>Invalid Credentials: Ensure GitHub secrets are set correctly</li> <li>Timeout Issues: If tests time out, increase the timeout value in the workflow file</li> <li>Incomplete Files: If files are incomplete, check for multi-part upload permissions or connectivity issues</li> </ul>"},{"location":"s3-testing/#diagnosing-multi-part-upload-issues","title":"Diagnosing Multi-part Upload Issues","text":"<p>If you encounter problems with multi-part uploads:</p> <ol> <li>Check S3 permissions include all required multi-part actions (AbortMultipartUpload, etc.)</li> <li>Verify no network interruptions occurred during upload</li> <li>Inspect the S3 bucket for incomplete multi-part uploads:    <code>bash    aws s3api list-multipart-uploads --bucket your-bucket-name</code></li> <li>Enable DEBUG logging in the collector to see detailed upload information</li> </ol>"},{"location":"s3-testing/#s3-uri-format","title":"S3 URI Format","text":"<p>The collector accepts S3 URIs in this format:</p> <pre><code>s3://BUCKET-NAME/PREFIX/\n</code></pre> <p>Example:</p> <pre><code>s3://unvariance-collector-test-irsa/test-run-123/\n</code></pre>"},{"location":"architecture/decisions/2024-12-21-container-notifications/","title":"2024-12-21: Notifications for container lifecycle events","text":""},{"location":"architecture/decisions/2024-12-21-container-notifications/#status","title":"Status","text":"<p>Draft, WIP</p>"},{"location":"architecture/decisions/2024-12-21-container-notifications/#context","title":"Context","text":"<p>We'd like the collector to show how memory resource contention influences container performance.</p> <p>To do that, we'd need to monitor: 1. Resource contention - can do this with <code>resctrl</code>, or by monitoring LLC Misses using perf counters 2. Container performance - current plan is to do this by monitoring CPI (cycles per instruction)</p> <p>For CPI monitoring, we'd need to have an inventory of containers on the system, and correctly instrument them as they arrive/go. In this issue, we add a component to monitor the arrival and departure of containers in the system.</p>"},{"location":"architecture/decisions/2024-12-21-container-notifications/#options-considered","title":"Options considered","text":""},{"location":"architecture/decisions/2024-12-21-container-notifications/#kubelet-api","title":"Kubelet API","text":"<p>If we're focusing on Kubernetes, kubelet provides an HTTP API accessible locally. This appears to be an undocumented, unstable API, that is nevertheless available in kubelet.</p> <p>Stack overflow discussion points to a project kubeletctl. The referenced blog post shows several <code>curl</code> commands to interact with the API. According to the blog post, this is available because the default kubelet configuration allows for anonymous (unauthenticated) requests, so this relies on users not fortifying their systems to this vulnerability. The specific implementation in kubeletctl appears a thin implementation of HTTP calls, so it might be best to reimplement this in our on library rather than take a dependency.</p> <p>Pros: - Should provide metadata on Pods, not only containers - Does not rely on a specific container runtime (docker, containerd, etc.)</p> <p>Cons: - Undocumented, unstable API - Requires access to kubelet, which may not be available in all environments - Appears to require polling (no <code>watch</code>). If so, will react slowly and incur more overhead.</p>"},{"location":"architecture/decisions/2024-12-21-container-notifications/#filesystem-watch-on-the-cgroup-directory-eg-inotify","title":"Filesystem watch on the cgroup directory (e.g., <code>inotify</code>)","text":"<p>This is the method used by Koordinator.sh in its PLEG component. It watches the cgroup root path for each of the Kubernetes QoS classes, for new pod directories. A new pod directory adds that pod subdirectory to a container watcher, which then issues container events.</p> <p>Pros: - Does not require access to kubelet - Does not depend on a container runtime - ABI is stable and well-documented - Supports inotify, which is efficient and low-overhead</p> <p>Cons: - Does not provide metadata beyond the pod and container IDs</p>"},{"location":"architecture/decisions/2024-12-21-container-notifications/#cri-container-runtime-interface-events","title":"CRI (Container Runtime Interface) events","text":""},{"location":"architecture/decisions/2024-12-21-container-notifications/#kubernetes-api-ie-watching-the-control-plane","title":"Kubernetes API (i.e., watching the control plane)","text":""},{"location":"architecture/decisions/2024-12-21-container-notifications/#decision","title":"Decision","text":""},{"location":"architecture/decisions/2025-01-02-aws-test-runners/","title":"2025-01-02: AWS test runners","text":""},{"location":"architecture/decisions/2025-01-02-aws-test-runners/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"architecture/decisions/2025-01-02-aws-test-runners/#context","title":"Context","text":"<p>We'd like to run some tests on AWS to check the availability of PMC (Performance Monitoring Counters) and Linux resctrl on different instance types. To do this, we'll want an automated way to run tests on different instance types.</p> <p>As of writing, the main check will be <code>cpi-count</code>, which checks the availability of cycles and instructions, and compares the results of <code>go-perf</code> and <code>perf</code> to sanity-check the results. </p> <p>In the future, we'll want to add more tests and similarly run them on different instance types. For example:</p> <ul> <li>Checking other counters than cycles and instructions (e.g., LLCMisses)</li> <li>Checking the availability of <code>resctrl</code> in Linux</li> <li>Verifying <code>resctrl</code> is able to control memory bandwidth and cache allocation</li> </ul> <p>This decision is about individual, relatively simple checks that run on a single instance. Tests that require complex workloads (e.g., DeathStarBench) are out of scope for this decision.</p>"},{"location":"architecture/decisions/2025-01-02-aws-test-runners/#options-considered-ec2-based","title":"Options considered - EC2 based","text":""},{"location":"architecture/decisions/2025-01-02-aws-test-runners/#common-pros-and-cons","title":"Common pros and cons","text":"<p>Pros:</p> <ul> <li>Easy to run multiple instances</li> <li>Gives control over the operating system and AMI, if we need that control in the future.</li> <li>Few components running on the VM, so this is less noisy and more conducive to benchmarking.</li> </ul> <p>Cons:</p> <ul> <li>Only works on AWS. Will require adaptation for other clouds.</li> </ul>"},{"location":"architecture/decisions/2025-01-02-aws-test-runners/#aws-ec2-with-user-data","title":"AWS EC2 with User Data","text":"<p>This is the strawman: spin up an EC2 instance, install the necessary tools, run the tests, and then tear down the instance. User Data is a way to run commands when the instance is first launched.</p> <p>Additional pros:</p> <ul> <li>None</li> </ul> <p>Additional cons:</p> <ul> <li>There is no good way to get results out of the instance.</li> <li>It is hard to check when tests are done.</li> </ul>"},{"location":"architecture/decisions/2025-01-02-aws-test-runners/#aws-ec2-with-a-github-self-hosted-runner","title":"AWS EC2 with a GitHub Self-Hosted Runner","text":"<p>This spins up an EC2 instance that runs a GitHub Actions runner. The runner is labeled specifically for the test that spins it up. The Action then runs the test workflow on the runner it just spun up. At the end of the test, the workflow tears down the runner.</p> <p>Additional pros:</p> <ul> <li>Integrated well with GitHub Actions: natively extracts results and continues the workflow when the test is done.</li> </ul> <p>Additional cons:</p> <ul> <li>More complex than EC2 with User Data (but solves that approach's problems).</li> </ul>"},{"location":"architecture/decisions/2025-01-02-aws-test-runners/#options-considered-kubernetes-based","title":"Options considered - Kubernetes based","text":""},{"location":"architecture/decisions/2025-01-02-aws-test-runners/#common-pros-and-cons_1","title":"Common pros and cons","text":"<p>Pros:</p> <ul> <li>We might be able to reuse this infrastructure for benchmarks with complex Kubernetes workloads.</li> </ul> <p>Cons:</p> <ul> <li>Complex. Need to set up a Kubernetes cluster and all its tooling.</li> <li>Less control over the operating system and AMI.</li> <li>Kubernetes has more components running on the Node (e.g., kubelet) that introduce noise, so this approach is less conducive to benchmarking.</li> </ul>"},{"location":"architecture/decisions/2025-01-02-aws-test-runners/#spin-up-a-kubernetes-cluster-and-run-the-tests-in-a-pod","title":"Spin up a Kubernetes cluster and run the tests in a pod","text":"<p>This is the approach the Cilium uses for its EKS conformance tests..</p> <p>Additional pros:</p> <ul> <li>Easy to check for completion and extract results (with <code>kubectl</code>).</li> </ul> <p>Additional cons:</p> <ul> <li>More components to set up and tear down (the Kubernetes control plane) which increases the time it takes to run tests and the cost of running tests.</li> <li>Need to write the functionality to extract results ourselves.</li> </ul>"},{"location":"architecture/decisions/2025-01-02-aws-test-runners/#maintain-a-persistent-kubernetes-cluster-with-actions-runner-controller","title":"Maintain a persistent Kubernetes cluster with <code>actions-runner-controller</code>","text":"<p>following GitHub's \"Autoscaling with self-hosted runners\":</p> <ul> <li>Run a Kubernetes cluster on one of the cloud providers</li> <li>Use GitHub Actions to trigger tests</li> <li>Tests run self hosted on the Kubernetes cluster. The actions-runner-controller seems to be the official controller for this.</li> <li>Each test that requires a specific node type will trigger a runner that only runs on that node type</li> </ul> <p>I believe we can add a nodeSelector in the AutoscalingRunnerSet from the values.yaml when deploying the controller (under template.spec). So this might require a controller deployment per node type.</p> <p>Additional pros:</p> <ul> <li>Very little spin-up and tear-down code, as the controller handles the scaling. This reulsts in simpler Actions, and more reliable cleanup.</li> <li>Tests run on GitHub Runners, so they extract results natively.</li> <li>We can spin up similar clusters on other clouds, and reuse the exact same Actions to run the tests on other clouds' instance types.</li> </ul> <p>Additional cons:</p> <ul> <li>Cluster is relatively complex: needs to anticipate all instance types we want to test on, and add controllers for each. This can be implemented with for loops in a helm chart, but still adds complexity.</li> <li>Cluster would be persistent, so it has ongoing cost, regardless of whether tests are running or not.</li> <li>The cluster would be maintained separately from the tests, so it might be hard to keep them in sync.</li> </ul>"},{"location":"architecture/decisions/2025-01-02-aws-test-runners/#replicatedcom-compatibility-matrix","title":"Replicated.com Compatibility Matrix","text":"<p>It is a service that spins up full Kubernetes clusters for testing, and bills by usage.</p> <p>Additional pros:</p> <ul> <li>Easy to spin up and tear down clusters.</li> <li>Support for AWS, GCP, Azure, OCI, as well as Openshift, RKE2, and k3s.</li> <li>Might have credits for open source projects (at least with Openshift)</li> </ul> <p>Additional cons:</p> <ul> <li>Needs Kubernetes tooling installed (which complicates the Github Action)</li> <li>Markup over using the clouds directly (although it is small)</li> <li>No spot instance support</li> </ul>"},{"location":"architecture/decisions/2025-01-02-aws-test-runners/#decision","title":"Decision","text":"<p>We'll use the EC2 + GitHub Actions Runner approach, because it is the simplest way that returns results and is easy to check for completion.</p>"},{"location":"architecture/decisions/2025-01-02-aws-test-runners/#consequences","title":"Consequences","text":""},{"location":"architecture/decisions/2025-01-02-aws-test-runners/#positive","title":"Positive","text":"<ul> <li>Can write the entire test as a GitHub Action.</li> <li>The same approach can be used for benchmarking.</li> <li>Can use AWS credits to run tests.</li> </ul>"},{"location":"architecture/decisions/2025-01-02-aws-test-runners/#negative","title":"Negative","text":"<ul> <li>We are currently just enabling AWS. To run on other clouds, the setup and cleanup would need to be updated.</li> </ul>"},{"location":"architecture/decisions/2025-01-02-aws-test-runners/#risks","title":"Risks","text":"<ul> <li>Making cleanup bulletproof would require iteration, which could lead to orphaned runners and their associated costs in the interim.</li> </ul>"},{"location":"architecture/decisions/2025-02-18-getting-cmt-measurements/","title":"2025-02-18: Collecting Intel CMT Measurements","text":""},{"location":"architecture/decisions/2025-02-18-getting-cmt-measurements/#context","title":"Context","text":"<p>We need to collect Intel CMT (Cache Monitoring Technology) measurements at millisecond granularity for containers in a cloud-native environment. </p>"},{"location":"architecture/decisions/2025-02-18-getting-cmt-measurements/#decision","title":"Decision","text":"<p>We will build a kernel module that interacts directly with Intel RDT MSRs (Model Specific Registers) to configure and read CMT measurements.</p>"},{"location":"architecture/decisions/2025-02-18-getting-cmt-measurements/#rationale","title":"Rationale","text":"<p>We considered three approaches for collecting CMT measurements:</p> <ol> <li> <p>Using Linux perf counters: After investigating the Intel CMT-CAT repository and relevant Linux kernel code, we found that although the Intel software repository seemed to support perf counters for CMT, the Linux kernel did not actually implement this. Therefore, using perf was not a viable option.</p> </li> <li> <p>Using the resctrl filesystem interface: The Linux kernel's resctrl subsystem provides a filesystem-based interface for configuring Intel RDT and reading measurements. However, this approach has several drawbacks:</p> </li> <li>Collecting measurements at millisecond granularity through the filesystem interface for all containers would be complex and potentially inefficient due to the overhead of system calls. </li> <li> <p>Resctrl is based on tasks and processes rather than containers. To use resctrl, we would need to build a system to monitor container lifecycle events and configure resctrl accordingly, which would add complexity and potential gaps in measurement.</p> </li> <li> <p>Building a kernel module to interact with MSRs directly: This approach offers several advantages:</p> </li> <li>By interacting with MSRs directly, the kernel module can read CMT information with very low overhead, without the layers of the filesystem interface.</li> <li>The kernel module can probe container lifecycle tracepoints to allocate RMIDs (Resource Monitoring IDs) and assign them to containers automatically.</li> <li>This approach enables a cloud-native solution that seamlessly measures containers as they are created.</li> </ol> <p>Given these considerations, we chose to build a kernel module that interacts with Intel RDT MSRs directly. This approach provides the best performance, flexibility, and compatibility with a cloud-native container environment.</p>"},{"location":"architecture/decisions/2025-02-18-getting-cmt-measurements/#consequences","title":"Consequences","text":"<p>Building a kernel module for CMT measurement has the following consequences:</p> <ul> <li>We will need to maintain the kernel module code and ensure compatibility with different Linux kernel versions.</li> <li>Users will need to load the kernel module to enable CMT measurement collection.</li> <li>We will have tight integration with container lifecycle events, enabling seamless measurement of containers.</li> <li>We can achieve low-overhead, millisecond-granularity measurement collection, meeting our performance requirements.</li> </ul>"},{"location":"architecture/decisions/2025-02-18-getting-cmt-measurements/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"architecture/decisions/2025-02-18-getting-cmt-measurements/#appendix-a-intel-cmt-cat-summary","title":"Appendix A: intel-cmt-cat summary","text":"<p>The <code>perf_monitoring.c</code> file:</p> <ul> <li>Checks if perf is available by checking if <code>/proc/sys/kernel/perf_event_paranoid</code> exists.</li> <li>Checks if RDT exists by reading <code>/sys/devices/intel_cqm/type</code><ul> <li>if it exists, its value (as integer) is the perf <code>type</code> field</li> <li>traverses <code>/sys/devices/intel_cqm/events</code> for events <code>llc_occupancy</code>, <code>local_bytes</code>, <code>total_bytes</code></li> <li>their value is parsed to get the <code>config</code> field of the perf struct</li> <li>the same file with extension <code>.scale</code> is used to read a <code>double</code> scale</li> </ul> </li> </ul>"},{"location":"architecture/decisions/2025-02-18-getting-cmt-measurements/#mentions-of-using-the-perf-command-line","title":"Mentions of using the perf command line","text":"<p>Here are references from the web for monitoring RDT using perf. However note that we found that the patches discussed in these references were not present in the Linux kernel whose code we checked (6.13.2) and appear to have not been merged into the kernel originally.</p> <p>A 2017 forum post was able to view events with <code>perf stat</code> as events:</p> <p><code>intel_cqm/llc_occupancy , intel_cqm/llc_local_bytes/,intel_cqm_total_bytes/</code></p> <p>(the last value seems to have a typo replacing <code>/</code> with <code>_</code>)</p> <p>An Intel/Kanaka Juvva presentation at LinuxCon'2015 shows per-application memory bandwidth monitoring with <code>perf</code> (slide 11):</p> <p>Two perf events are exported to userland - LOCAL_BW   - perf stat \u2013e intel_cqm/llc_local_bw/ -a \u201cmy_application\u201d - TOTAL_BW   - perf stat \u2013e intel_cqm/llc_total_bw/ -a \u201cmy_application\u201d</p> <p>A 2016 Kanaka Juuva presentation: - further mentions LLC Occupancy - shows memory bandwidth benchmark results - shows more process-based CLI examples, by PID:</p> <ul> <li>LLC_OCCUPANCY</li> <li>perf stat \u2013e intel_cqm/llc_occupancy/ -p \u201cpid of my_application\u201d</li> <li>discusses cgroups-based measurements. This might have been before the switch from cgroup to resctrl.</li> </ul>"},{"location":"architecture/decisions/2025-02-18-getting-cmt-measurements/#appendix-b-a-journey-through-intel-cmt-cat","title":"Appendix B: A journey through intel-cmt-cat","text":"<p>The intel-cmt-cat repo documentation suggests perf can read CMT data as well (table 5 in README).</p> <p>In this section, we look into how intel-cmt-cat uses perf, and document its usage so we can support that alongside the other counters.</p> <p>We start with the <code>pqos</code> CLI tool. Its command line parameters set up calls into the library in <code>lib/</code>:</p> <ul> <li><code>main</code> calls <code>selfn_monitor_cores</code> on the <code>-m</code> command line option.</li> <li><code>parse_monitor_cores</code> parses the <code>-m</code> command line option.</li> <li><code>parse_monitor_group</code> parses a string from the command line to a list of cores or pids, and calls <code>grp_add</code> on each.</li> <li><code>grp_add</code> allocates a <code>struct mon_group</code> called <code>new_grp</code> on the stack, then adds the core/pid/channel/etc. to the group using <code>grp_set_*</code>, and then appends it to a global variable <code>sel_monitor_group</code>.</li> <li>later, <code>main</code> calls <code>monitor_setup</code></li> <li><code>monitor_setup</code> calls the library API depending on the type of monitor. For cores, it calls <code>pqos_mon_start_cores</code>.</li> </ul> <p>Going into the library:</p> <ul> <li><code>pqos_mon_start_cores</code> calls <code>pqos_mon_start_cores_ext</code> (which also has an opt parameter)</li> <li><code>pqos_mon_start_cores_ext</code> checks input validity and then makes an <code>API_CALL(mon_start_cores...)</code></li> <li><code>API_CALL</code> is a macro that accesses a virtual table of monitoring operations called <code>api</code> in <code>api.c</code>. <ul> <li>This <code>api</code> variable is initialized in <code>api_init</code> to either the OS interface or MSR interface (these are mentioned in the repo's README).</li> <li>In the OS interface, the <code>mon_start_cores</code> function pointer is initialized to point to <code>os_mon_start_cores</code>.</li> </ul> </li> <li><code>os_mon_start_cores</code> validates the input, the available monitoring capabilities, and ensures the monitoring hadn't already started, and calls <code>os_mon_start_events</code>.</li> <li><code>os_mon_start_events</code>:<ul> <li>runs <code>perf_mon_is_event_supported</code> on every event, and if so, calls <code>perf_mon_start</code>.</li> <li>otherwise, checks <code>resctrl_mon_is_event_supported</code> and if so performs <code>resctrl_mon_start</code>.</li> </ul> </li> </ul> <p>Let's explore the flow that checks perf for supported events:</p> <ul> <li><code>perf_mon_is_event_supported</code> calls <code>get_supported_event</code>.</li> <li><code>get_supported_event</code> looks up the event in a global <code>events_tab</code>.<ul> <li>the first event in <code>events_tab</code> is <code>llc_occupancy</code>.</li> </ul> </li> </ul> <p>Initialization of perf monitoring in <code>perf_mon_init</code>:</p> <ul> <li>if <code>/proc/sys/kernel/perf_event_paranoid</code> exists, enables the PMU events (cycles, instructions, IPC, LLC misses, LLC references).</li> <li><code>set_arch_event_attrs</code> sets the <code>attr</code> field on PMU events. The <code>attr</code> field is a <code>struct perf_event_attr</code> (from the linux API).</li> <li><code>set_mon_type</code> reads <code>/sys/devices/intel_cqm/type</code> as an integer into the global variable <code>os_mon_type</code>. This int is then used in the perf attr as its <code>type</code> field in <code>set_rdt_event_attrs</code>.</li> <li><code>set_mon_events</code> then traverses the directory <code>/sys/devices/intel_cqm/events</code>. <ul> <li>For each file, it tries to find an entry in <code>events_tab</code> whose <code>name</code> field is the same as the file name. </li> <li>For every match, it calls <code>set_rdt_event_attrs</code>.</li> </ul> </li> <li><code>set_rdt_event_attrs</code><ul> <li>reads the file</li> <li>assumes the contents has a <code>=</code>, discards everything before the first <code>=</code> and parses the rest as an integer. this will be <code>attrs.config</code></li> <li>reads another file filename+<code>.scale</code> suffix</li> <li>parses it as a double. this will be the event's <code>scale</code></li> </ul> </li> </ul> <p>So far, we covered initialization and checking event availability. Now let's see how the library configures the kernel to start monitoring:</p> <ul> <li><code>perf_event_open</code> makes the syscall via <code>syscall(__NR_perf_event_open, attr, pid, cpu, group_fd, flags)</code></li> </ul>"},{"location":"ci/aws-setup/","title":"AWS Setup for CI Testing","text":"<p>Our CI system needs to test the collector on various AWS instance types to validate hardware-specific features. We use GitHub Actions to dynamically spin up EC2 instances with specific hardware configurations, run our tests, and then tear down the instances.</p>"},{"location":"ci/aws-setup/#overview","title":"Overview","text":"<p>The CI system uses two key community actions: - machulav/EC2-github-runner: Manages ephemeral EC2 instances for test execution - aws-actions/configure-aws-credentials: Handles AWS authentication through GitHub's OIDC provider</p> <p>Each test workflow creates a dedicated GitHub Actions runner on a fresh EC2 instance. This ensures our tests run in clean environments with specific hardware configurations.</p>"},{"location":"ci/aws-setup/#aws-account-setup","title":"AWS Account Setup","text":"<p>We maintain a dedicated AWS account for CI testing to isolate these resources from production environments. This separation provides clearer cost tracking and stronger security boundaries.</p>"},{"location":"ci/aws-setup/#administrative-access","title":"Administrative Access","text":"<p>After creating the dedicated CI testing account, set up administrative access:</p> <ol> <li>In the root account, navigate to IAM Identity Center</li> <li>Create a new user in the IAM Identity Center</li> <li>Create a Permission Set or use the existing \"Administrator Access\" permission set</li> <li>Note: \"Power User Access\" is insufficient as it doesn't allow IAM role creation</li> <li>Assign the user to the CI testing account with the Administrator Access permission set</li> </ol> <p>The Administrator Access permission set is required for subsequent IAM configuration steps. While Power User Access might seem sufficient, it lacks the necessary permissions for creating IAM roles needed for GitHub Actions integration.</p>"},{"location":"ci/aws-setup/#iam-configuration","title":"IAM Configuration","text":"<p>First, configure GitHub as an OIDC provider to enable secure authentication:</p> <ol> <li>Open the IAM console</li> <li>Navigate to \"Identity Providers\" and add a new provider</li> <li>Select \"OpenID Connect\"</li> <li>Use <code>https://token.actions.githubusercontent.com</code> as the provider URL</li> <li>Set the audience to <code>sts.amazonaws.com</code></li> </ol> <p>Next, create an IAM role for GitHub Actions:</p> <ol> <li>Create a new role</li> <li>Set the Trusted entity type to Web Identity</li> <li>Select the GitHub OIDC provider as the trust entity</li> <li>Fill in the org (<code>unvariance</code>) and repo (<code>collector</code>), not filling in the branch</li> <li>Add no permissions (we will do this in a moment)</li> <li>Name the role, e.g., <code>github-actions-collector</code>.</li> <li>Verify the generated trusted entities to be:</li> </ol> <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n                \"Federated\": \"arn:aws:iam::&lt;ACCOUNT-ID&gt;:oidc-provider/token.actions.githubusercontent.com\"\n            },\n            \"Action\": \"sts:AssumeRoleWithWebIdentity\",\n            \"Condition\": {\n                \"StringEquals\": {\n                    \"token.actions.githubusercontent.com:aud\": \"sts.amazonaws.com\"\n                },\n                \"StringLike\": {\n                    \"token.actions.githubusercontent.com:sub\": \"repo:unvariance/collector:*\"\n                }\n            }\n        }\n    ]\n}\n</code></pre>"},{"location":"ci/aws-setup/#ec2-permissions","title":"EC2 Permissions","text":"<p>The IAM role needs permissions to manage EC2 instances and request Spot instances. Attach a policy with these minimum permissions:</p> <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"ec2:RunInstances\",\n                \"ec2:TerminateInstances\",\n                \"ec2:DescribeInstances\",\n                \"ec2:DescribeInstanceStatus\",\n                \"ec2:RequestSpotInstances\",\n                \"ec2:CancelSpotInstanceRequests\",\n                \"ec2:DescribeSpotInstanceRequests\",\n                \"ec2:DescribeSpotPriceHistory\"\n            ],\n            \"Resource\": \"*\"\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": \"ec2:CreateTags\",\n            \"Resource\": \"*\",\n            \"Condition\": {\n                \"StringEquals\": {\n                    \"ec2:CreateAction\": [\n                        \"RunInstances\",\n                        \"RequestSpotInstances\"\n                    ]\n                }\n            }\n        }\n    ]\n}\n</code></pre>"},{"location":"ci/aws-setup/#allowing-spot-instances","title":"Allowing Spot instances","text":"<p>According to AWS spot instance role docs:</p> <p>Under most circumstances, you don't need to manually create a service-linked role. Amazon EC2 creates the\u00a0AWSServiceRoleForEC2Spot\u00a0service-linked role the first time you request a Spot Instance using the console.</p> <p>And later:</p> <p>If you use the AWS CLI or an API to request a Spot Instance, you must first ensure that this role exists.</p> <p>So to enable Spot instances, we recommend making a request on the account using the console, which creates the role, and then canceling the request.</p>"},{"location":"ci/aws-setup/#instance-quotas","title":"Instance quotas","text":"<p>We found default EC2 and Spot quotas to be smaller than most machines that make the PMU available to VMs. We requested an increase to 192 cores.</p> <p>Quota requests can be made through this page. Note that there are separate quotas for On-Demand and for Spot.</p>"},{"location":"ci/aws-setup/#network-configuration","title":"Network Configuration","text":"<p>Create a dedicated VPC for CI testing:</p> <ol> <li>Create a new VPC with a single public subnet</li> <li>Set up appropriate security groups to allow:</li> <li>Outbound traffic on port 443 for communication with GitHub</li> </ol>"},{"location":"ci/aws-setup/#repository-variables","title":"Repository variables","text":"<p>Configure the repository with the following secrets that can be used in Actions:</p> <ul> <li><code>AWS_ROLE_ARN</code>: the ARN of the role that allows running and terminating instances</li> <li><code>AWS_REGION</code>: the region where we'll run runners</li> <li><code>AWS_SUBNET_ID</code>: the subnet ID, needs to be in <code>AWS_REGION</code></li> <li><code>AWS_SECURITY_GROUP_ID</code>: the name of the security group that allows runners to pull jobs</li> <li><code>REPO_ADMIN_TOKEN</code>: see below</li> </ul>"},{"location":"ci/aws-setup/#getting-a-token-for-ec2-github-runner","title":"Getting a token for ec2-github-runner","text":"<p>To register runners with GitHub, the <code>machulav/ec2-github-runner</code> action needs a GitHub token that has permissions to modify the the repository's set of self hosted runners. This might be transferable to user accounts but I haven't checked.</p> <p>A discussion thread implies that finer-grained permissions might be available, where a token would only be able to configure runners rather than full Administration privileges, but it didn't work.</p> <ol> <li>Configure your organization to allow fine-grained tokens. In Organization Settings -&gt; Third-party Access -&gt; Personal access tokens -&gt; Settings, allow access via fine-grained personal access tokens</li> <li>Create a fine-grained personal access token here: https://github.com/settings/personal-access-tokens/new</li> <li>Set the resource owner to be the organization</li> <li>Set the permission scope to \"Only select repositories\", and select the repo with the GitHub Action</li> <li>In Repository permissions, add \"Administration\" (read and write)</li> </ol>"},{"location":"ci/aws-setup/#github-workflow-configuration","title":"GitHub Workflow Configuration","text":"<p>For an example workflow, adapted from the ec2-github-runner README and configure-aws-credentials README example, see <code>/.github/workflows/aws-runner-template.yaml</code>.</p>"}]}